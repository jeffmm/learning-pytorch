{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incredible-rings",
   "metadata": {},
   "source": [
    "## COCO dataset validation using Faster-RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "imported-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import torch\n",
    "import tqdm\n",
    "import torchvision.datasets as dset\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import ToTensor, Compose\n",
    "from torchvision.datasets import CocoDetection\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "killing-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "respected-blanket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.23s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_val = dset.CocoDetection(root=\"../data/coco/val2017/\",\n",
    "                              annFile=\"../data/coco/annotations/instances_val2017.json\",\n",
    "                              transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "selected-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "western-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since images are different sizes, must keep batch size to 1...\n",
    "coco_val_dl = torch.utils.data.DataLoader(coco_val, batch_size=1, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "victorian-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(coco_dataloader, model):\n",
    "    # Prepare a dictionary of counts for each category\n",
    "    counts = {}\n",
    "    for cid in coco_dataloader.dataset.coco.cats.keys():\n",
    "        counts[cid] = 0\n",
    "    results = []\n",
    "    model.eval()\n",
    "    dl = tqdm.tqdm(coco_dataloader)\n",
    "    with torch.no_grad():\n",
    "        for X, y in dl:\n",
    "            pred = model(X.to(device))\n",
    "            # For some reason, some images return empty labels (?)\n",
    "            if not y:\n",
    "                continue\n",
    "            image_id = y[0]['image_id'].item()\n",
    "            # Record instances of each category\n",
    "            for gt in y:\n",
    "                cid = gt['category_id'].item()\n",
    "                counts[cid] += 1\n",
    "            for p in pred:\n",
    "                for label, box, score in zip(p['labels'].tolist(), p['boxes'].tolist(), p['scores'].tolist()):\n",
    "                    res = {'image_id': image_id}\n",
    "                    res['category_id'] = label\n",
    "                    # Convert to x, y, width, height\n",
    "                    res['bbox'] = [box[0], box[1], box[2] - box[0], box[3] - box[1]]\n",
    "                    res['score'] = score\n",
    "                    results.append(res)\n",
    "    return results, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "motivated-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results, counts = validation_loop(coco_val_dl, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "exceptional-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"results.json\", \"w\") as f:\n",
    "#    json.dump(results, f)\n",
    "#with open(\"counts.json\", \"w\") as f:\n",
    "#    json.dump(counts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "systematic-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.json\", \"r\") as f:\n",
    "    results = json.load(f)\n",
    "with open(\"counts.json\", \"r\") as f:\n",
    "    counts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "accredited-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = set()\n",
    "cat_ids = set()\n",
    "for res in results:\n",
    "    img_ids.add(res['image_id'])\n",
    "    cat_ids.add(res['category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "proper-minneapolis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=1.67s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_res = coco_val.coco.loadRes(\"results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "charged-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_eval = COCOeval(cocoGt=coco_val.coco, cocoDt=coco_res, iouType='bbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "sharing-rings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "handy-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_summarize(coco_eval, ap=1, iouThr=None, areaRng='all', maxDets=100 ):\n",
    "    p = coco_eval.params\n",
    "    iStr = ' {:<18} {} @[ IoU={:<9} | area={:>6s} | maxDets={:>3d} ] = {:0.3f}'\n",
    "    titleStr = 'Average Precision' if ap == 1 else 'Average Recall'\n",
    "    typeStr = '(AP)' if ap==1 else '(AR)'\n",
    "    iouStr = '{:0.2f}:{:0.2f}'.format(p.iouThrs[0], p.iouThrs[-1]) \\\n",
    "        if iouThr is None else '{:0.2f}'.format(iouThr)\n",
    "    \n",
    "    aind = [i for i, aRng in enumerate(p.areaRngLbl) if aRng == areaRng]\n",
    "    mind = [i for i, mDet in enumerate(p.maxDets) if mDet == maxDets]\n",
    "    if ap == 1:\n",
    "        # dimension of precision: [TxRxKxAxM]\n",
    "        s = coco_eval.eval['precision']\n",
    "        # IoU\n",
    "        if iouThr is not None:\n",
    "            t = np.where(iouThr == p.iouThrs)[0]\n",
    "            s = s[t]\n",
    "        s = s[:,:,:,aind,mind]\n",
    "    else:\n",
    "        # dimension of recall: [TxKxAxM]\n",
    "        s = coco_eval.eval['recall']\n",
    "        if iouThr is not None:\n",
    "            t = np.where(iouThr == p.iouThrs)[0]\n",
    "            s = s[t]\n",
    "        s = s[:,:,aind,mind]\n",
    "    if len(s[s>-1])==0:\n",
    "        mean_s = -1\n",
    "    else:\n",
    "        mean_s = np.mean(s[s>-1])\n",
    "    return mean_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "lonely-darkness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=21.26s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=3.28s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.50 | area=   all | maxDets=100 ] = 0.586\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.50 | area= small | maxDets=100 ] = 0.368\n",
      " Average Precision  (AP) @[ IoU=0.50:0.50 | area=medium | maxDets=100 ] = 0.634\n",
      " Average Precision  (AP) @[ IoU=0.50:0.50 | area= large | maxDets=100 ] = 0.715\n",
      " Average Recall     (AR) @[ IoU=0.50:0.50 | area=   all | maxDets=  1 ] = 0.436\n",
      " Average Recall     (AR) @[ IoU=0.50:0.50 | area=   all | maxDets= 10 ] = 0.725\n",
      " Average Recall     (AR) @[ IoU=0.50:0.50 | area=   all | maxDets=100 ] = 0.771\n",
      " Average Recall     (AR) @[ IoU=0.50:0.50 | area= small | maxDets=100 ] = 0.533\n",
      " Average Recall     (AR) @[ IoU=0.50:0.50 | area=medium | maxDets=100 ] = 0.824\n",
      " Average Recall     (AR) @[ IoU=0.50:0.50 | area= large | maxDets=100 ] = 0.914\n"
     ]
    }
   ],
   "source": [
    "coco_eval.params.areaRng = [[0, 1e8]]\n",
    "coco_eval.params.areaRngLbl = ['all']\n",
    "coco_eval.params.maxDets = [100]\n",
    "coco_eval.params.iouThrs = [0.5]\n",
    "coco_eval.params.imgIds = list(img_ids)\n",
    "coco_eval.params.catIds = list(cat_ids)\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "several-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "precisions = []\n",
    "recalls = []\n",
    "# IoU threshold\n",
    "for cid in cat_ids:\n",
    "    coco_eval.params.catIds = [cid]\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    precisions.append(coco_summarize(coco_eval))\n",
    "    recalls.append(coco_summarize(coco_eval, ap=0))\n",
    "precisions = np.array(precisions)\n",
    "recalls = np.array(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "portuguese-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = 2 * precisions * recalls / (precisions + recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "excess-genome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Category\t   F1   \tInstances\n",
      "\n",
      "      hair drier \t0.1164  \t11\n",
      "           spoon \t0.3449  \t253\n",
      "         handbag \t0.3670  \t540\n",
      "           apple \t0.3797  \t239\n",
      "           knife \t0.3811  \t326\n",
      "        backpack \t0.3846  \t371\n",
      "        scissors \t0.4088  \t36\n",
      "            book \t0.4106  \t1161\n",
      "           bench \t0.4299  \t413\n",
      "      toothbrush \t0.4658  \t57\n",
      "          carrot \t0.4996  \t371\n",
      "         hot dog \t0.5134  \t127\n",
      "         toaster \t0.5216  \t9\n",
      "          banana \t0.5232  \t379\n",
      "          orange \t0.5259  \t287\n",
      "           chair \t0.5295  \t1791\n",
      "    dining table \t0.5377  \t697\n",
      "            skis \t0.5421  \t241\n",
      "        broccoli \t0.5444  \t316\n",
      "          remote \t0.5457  \t283\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "k_lowest = np.argsort(f1_scores)[:k]\n",
    "bad_cats = np.array(list(cat_ids))[k_lowest]\n",
    "bad_cat_dict = {coco_val.coco.cats[cid]['name']: cid for cid in bad_cats}\n",
    "print(f\"{'Category': >16}\\t{'F1': >5}   \\tInstances\\n\")\n",
    "for cid, low in zip(bad_cats, k_lowest):\n",
    "    print(f\"{coco_val.coco.cats[cid]['name']: >16}\", f\"\\t{f1_scores[low]:0.04f}  \\t{counts[str(cid)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "critical-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "coco_eval.params.catIds = list(cat_ids)\n",
    "\n",
    "bad_cat_imgs = []\n",
    "\n",
    "for cid in bad_cats:\n",
    "    cat_img_ids = set()\n",
    "    coco_eval.params.catIds = [cid]\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    cat_imgs = np.where(coco_eval.evalImgs)[0]\n",
    "    for cimg in cat_imgs:\n",
    "        cat_img_ids.add(coco_eval.evalImgs[cimg]['image_id'])\n",
    "    bad_cat_imgs.append(sorted(list(cat_img_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "owned-driver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "nuclear-synthesis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=22.59s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=1.24s).\n"
     ]
    }
   ],
   "source": [
    "coco_eval = COCOeval(cocoGt=coco_val.coco, cocoDt=coco_res, iouType='bbox')\n",
    "\n",
    "# IoU threshold\n",
    "coco_eval.params.catIds = list(cat_ids)\n",
    "coco_eval.params.imgIds = list(img_ids)\n",
    "coco_eval.params.maxDets = [100]\n",
    "coco_eval.params.iouThrs = [0.5]\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "mobile-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_from_id(iid):\n",
    "    ind = np.where(np.array(coco_val.ids) == iid)[0][0]\n",
    "    img, ann = coco_val[ind]\n",
    "    return img.squeeze().permute(1, 2, 0).numpy().copy(), ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "graphic-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_cat_imgs = [list(set(coco_val.coco.catToImgs[cat])) for cat in bad_cats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "million-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_by_img = {}\n",
    "for res in results:\n",
    "    if results_by_img.get(res['image_id']):\n",
    "        results_by_img[res['image_id']].append(res)\n",
    "    else:\n",
    "        results_by_img[res['image_id']] = [res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "pregnant-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_bad_cat_images(cat_name, output_dir=Path(\"../data/coco_val_results/\"), draw_bboxes=True, show_images=False):\n",
    "    outdir = Path(output_dir) / f\"{cat_name}\"\n",
    "    outdir.mkdir(exist_ok=True)\n",
    "    cid = bad_cat_dict[cat_name]\n",
    "    cat_imgs = bad_cat_imgs[np.where(bad_cats == cid)[0][0]]\n",
    "    for iid in cat_imgs:\n",
    "        metrics = coco_eval.evaluateImg(iid, cid, [0, 1e6], 1000)\n",
    "        if metrics['gtMatches'].any():\n",
    "            continue\n",
    "        img_res = results_by_img[iid]\n",
    "        img, anns = get_img_from_id(iid)\n",
    "        if draw_bboxes:\n",
    "            for res in anns:\n",
    "                if res['category_id'] == cid:\n",
    "                    bx, by, w, h = np.array(res['bbox'], dtype=int)\n",
    "                    img = cv.rectangle(img, (bx, by), (bx+w, by+h), color=[1, 0, 0], thickness=3)\n",
    "            for res in img_res:\n",
    "                if res['category_id'] == cid:\n",
    "                    bx, by, w, h = np.array(res['bbox'], dtype=int)\n",
    "                    img = cv.rectangle(img, (bx, by), (bx+w, by+h), color=[0, 1, 1], thickness=2)\n",
    "        if show_images:\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            plt.imshow(img)\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        img = (np.round(img * 255)).astype(np.uint8)\n",
    "        cv.imwrite(str(outdir / f\"{iid}.jpg\"), cv.cvtColor(img, cv.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "diagnostic-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = Path(\"../data/coco_val_results/unlabeled\")\n",
    "img_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "exceptional-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_name in [\"dining table\", \"handbag\", \"backpack\", \"bench\", \"chair\", \"hair drier\"]:\n",
    "    write_bad_cat_images(cat_name, output_dir=img_dir, draw_bboxes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-spain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_eval.evaluate_image(cid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
