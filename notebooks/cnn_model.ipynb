{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "roman-hardware",
   "metadata": {},
   "source": [
    "## Using a CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "three-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "convenient-disco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "consecutive-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following the same code as in training_a_model notebook, but using a CNN model\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"../data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"../data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stainless-glasgow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at a sample of the data\n",
    "x, y = next(iter(training_data))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(x.squeeze(), cmap=\"gray\")\n",
    "plt.title(labels_map[y])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "powerful-bathroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (relu): ReLU()\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution kernel\n",
    "        self.relu = nn.ReLU()\n",
    "        # The output of a convo layer will be (W - K + 2P) / S + 1, where W is the\n",
    "        # image size, K is the kernel size, P is the padding size, and S is the stride.\n",
    "        # My input images are 1 x 28 x 28 and will be output as 6 x 30 x 30.\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=3, stride=1, padding=2)\n",
    "        # The output of a pooling layer will be (W - K) / S + 1, where K is the pooling kernel\n",
    "        # and S is the stride. So input 6 x 30 x 30 images will be output as 6 x 14 x 14.\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Input: 6 x 14 x 14, Output: 16 x 12 x 12\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=3, stride=1)\n",
    "        # Input: 16 x 12 x 12, Output: 16 x 6 x 6\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Fully connected layers. All 16*6*6 inputs connect to 120 outputs, connecting the\n",
    "        # convolutional layers to the FC layers.\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
    "        # 120 input nodes to 84 output nodes\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        # 84 input nodes to 10 output nodes: the number of labels\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "proper-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "convinced-edgar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (relu): ReLU()\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the dataloaders and model\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "model = Net()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "controlled-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,  momentum=momentum, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "adjacent-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Get the input data X and label y from the dataloader\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute the model prediction given current model parameters.\n",
    "        pred = model(X.to(device))\n",
    "        # Compute the loss from the prediction and the label\n",
    "        loss = loss_fn(pred, y.to(device))\n",
    "\n",
    "        # Optimization: zero gradients, backpropogation, adjust parameters.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    # Turn off grad computation to reduce overhead of forward pass for testing.\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X.to(device))\n",
    "            # Accumulate the total loss on the test data.\n",
    "            test_loss += loss_fn(pred, y.to(device)).item()\n",
    "            # Count the number of correct answers to calculate the accuracy.\n",
    "            correct += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\n",
    "\n",
    "    # Compute average loss and the overall accuracy of the model.\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "welcome-credit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 17.2%, Avg loss: 0.036040 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 0.014718 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 73.3%, Avg loss: 0.011319 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 75.2%, Avg loss: 0.010288 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 78.5%, Avg loss: 0.009201 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.008522 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.007986 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.007564 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 82.7%, Avg loss: 0.007327 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Test Error: \n",
      " Accuracy: 83.5%, Avg loss: 0.007090 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-mobility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-investigator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
